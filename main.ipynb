{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":26,"metadata":{"id":"PQKZMFYFavcU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670499563057,"user_tz":-540,"elapsed":7750,"user":{"displayName":"Juyeon Kim","userId":"17747853872644742840"}},"outputId":"6efefe63-d024-4748-8dde-16e8cd8c7b04"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["cd /content/drive/MyDrive/Colab Notebooks/Stable-Style-Transformer"],"metadata":{"id":"Thkbhh4CyjXw","executionInfo":{"status":"ok","timestamp":1670499563058,"user_tz":-540,"elapsed":10,"user":{"displayName":"Juyeon Kim","userId":"17747853872644742840"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7e405a48-c87d-4eaf-cb40-7342c2808940"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/Stable-Style-Transformer\n"]}]},{"cell_type":"code","source":["pwd"],"metadata":{"id":"RTvQ6wFly3E1","executionInfo":{"status":"ok","timestamp":1670499563058,"user_tz":-540,"elapsed":9,"user":{"displayName":"Juyeon Kim","userId":"17747853872644742840"}},"colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"c39d8621-6db0-462e-a9ec-f4fa915bbe5b"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/Colab Notebooks/Stable-Style-Transformer'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import re\n","import urllib.request\n","# from konlpy.tag import Okt\n","from tqdm import tqdm\n","    \n","urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", filename=\"ratings_train.txt\")\n","urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", filename=\"ratings_test.txt\")\n","train_data = pd.read_table('ratings_train.txt')\n","test_data = pd.read_table('ratings_test.txt')\n","\n","# 중복 제거 및 공백 제거\n","train_data.drop_duplicates(subset=['document'], inplace=True)\n","train_data = train_data.dropna(how = 'any')"],"metadata":{"id":"rvOQBOnYy3z-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !pip install konlpy"],"metadata":{"id":"J_GfEN7R78zV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data = train_data.iloc[:,1:]\n","train_data\n","# train_data[train_data['label'] == 0]"],"metadata":{"id":"qUTLJ1cq8AOi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_neg = train_data[train_data['label'] == 0]['document']\n","train_neg"],"metadata":{"id":"hiLxf-h08GAE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_pos = train_data[train_data['label'] == 1]['document']\n","train_pos"],"metadata":{"id":"KqIKg1v-855s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_pos_dataset = np.array(train_pos)\n","train_pos_dataset[0]"],"metadata":{"id":"DMHXVJWAARFm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pwd"],"metadata":{"id":"uO7Q4fTZ9Aon"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"id":"BSO5ov9r-_LS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# classifier - train_juyeon.py 이용해서 학습함\n","# !python ./generation_model/yelp/classifier/train_juyeon.py"],"metadata":{"id":"u5UAFvxV-6uR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python ./generation_model/yelp/train_juyeon.py "],"metadata":{"id":"llRMuN_364ZZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670502468598,"user_tz":-540,"elapsed":51977,"user":{"displayName":"Juyeon Kim","userId":"17747853872644742840"}},"outputId":"a98344c0-1c6e-4ab8-f73f-c11bc0415dc2"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/transformers/generation_tf_utils.py:24: FutureWarning: Importing `TFGenerationMixin` from `src/transformers/generation_tf_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import TFGenerationMixin` instead.\n","  warnings.warn(\n","2022-12-08 12:27:05.638816: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--skt--kogpt2-base-v2/snapshots/d0c0df48bf2b2c9350dd855021a5b216f560c0c7/tokenizer.json\n","loading file added_tokens.json from cache at None\n","loading file special_tokens_map.json from cache at None\n","loading file tokenizer_config.json from cache at None\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--skt--kogpt2-base-v2/snapshots/d0c0df48bf2b2c9350dd855021a5b216f560c0c7/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n","  \"_num_labels\": 1,\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n","  \"bos_token_id\": 0,\n","  \"created_date\": \"2021-04-28\",\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"license\": \"CC-BY-NC-SA 4.0\",\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"pad_token_id\": 3,\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"transformers_version\": \"4.25.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 51200\n","}\n","\n","The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n","The class this function is called from is 'PreTrainedTokenizerFast'.\n","loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--skt--kogpt2-base-v2/snapshots/d0c0df48bf2b2c9350dd855021a5b216f560c0c7/tokenizer.json\n","loading file added_tokens.json from cache at None\n","loading file special_tokens_map.json from cache at None\n","loading file tokenizer_config.json from cache at None\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--skt--kogpt2-base-v2/snapshots/d0c0df48bf2b2c9350dd855021a5b216f560c0c7/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n","  \"_num_labels\": 1,\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n","  \"bos_token_id\": 0,\n","  \"created_date\": \"2021-04-28\",\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"license\": \"CC-BY-NC-SA 4.0\",\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"pad_token_id\": 3,\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"transformers_version\": \"4.25.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 51200\n","}\n","\n","The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n","The class this function is called from is 'PreTrainedTokenizerFast'.\n","  0% 0/72840 [00:00<?, ?it/s]relu 수정17\n","> /content/drive/MyDrive/Colab Notebooks/Stable-Style-Transformer/generation_model/yelp/train_juyeon.py(172)main()\n","-> gen_trainer.zero_grad()\n","(Pdb) n\n","> /content/drive/MyDrive/Colab Notebooks/Stable-Style-Transformer/generation_model/yelp/train_juyeon.py(173)main()\n","-> gen_cls_loss.backward() # retain_graph=True\n","(Pdb) n\n","/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py:197: UserWarning: Error detected in AddmmBackward0. Traceback of forward call that caused the error:\n","  File \"./generation_model/yelp/train_juyeon.py\", line 192, in <module>\n","    main()\n","  File \"./generation_model/yelp/train_juyeon.py\", line 147, in main\n","    dec_out, vocab_out = genmodel.decoder(enc_out, token_idx, attribute)\n","  File \"/content/drive/MyDrive/Colab Notebooks/Stable-Style-Transformer/generation_model/yelp/gen_model.py\", line 124, in decoder\n","    vocab_out = self.matrix_D(dec_out).clone() # (dec_len+2, batch, n_vocab)\n","  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\", line 114, in forward\n","    return F.linear(input, self.weight, self.bias)\n","  File \"/usr/local/lib/python3.8/dist-packages/torch/fx/traceback.py\", line 57, in format_stack\n","    return traceback.format_stack()\n"," (Triggered internally at ../torch/csrc/autograd/python_anomaly_mode.cpp:114.)\n","  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [768, 51200]], which is output 0 of AsStridedBackward0, is at version 2; expected version 1 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!\n","> /content/drive/MyDrive/Colab Notebooks/Stable-Style-Transformer/generation_model/yelp/train_juyeon.py(173)main()\n","-> gen_cls_loss.backward() # retain_graph=True\n","(Pdb) q\n","  0% 0/72840 [00:33<?, ?it/s]\n","Traceback (most recent call last):\n","  File \"./generation_model/yelp/train_juyeon.py\", line 192, in <module>\n","    main()\n","  File \"./generation_model/yelp/train_juyeon.py\", line 173, in main\n","    gen_cls_loss.backward() # retain_graph=True\n","  File \"/usr/lib/python3.8/bdb.py\", line 94, in trace_dispatch\n","    return self.dispatch_exception(frame, arg)\n","  File \"/usr/lib/python3.8/bdb.py\", line 174, in dispatch_exception\n","    if self.quitting: raise BdbQuit\n","bdb.BdbQuit\n"]}]},{"cell_type":"code","source":["from transformers import *\n","gpt_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"],"metadata":{"id":"z1DHrWcb_dLL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"1OczGtqJNWtc"},"execution_count":null,"outputs":[]}]}